---
title: "Data and Causal Model"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Data and Causal Model}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(eval = FALSE)
```


## Data structure and causal Model

The purpose of the following case-studies is to demonstrate the core functionalities of the data structure in `DoubleML`. 

`DoubleML` provides interfaces to `data.table`, `data.frame` and base R `matrix`. The usage of the interfaces is
demonstrated in the following. We load the 401(k) data set.

```{r}
df_401k = load_401k()
head(df_401k)
```

### Example: Partially linear regression (PLR) models

Exemplarily we specify a partially linear regression model (PLR). Partially linear regression (PLR) models take the form
\begin{align*}
Y &= D \theta_0 + g_0(X) + \zeta, & &\mathbb{E}(\zeta | D,X) = 0,\\
D &= m_0(X) + V, & &\mathbb{E}(V | X) = 0,
\end{align*}
where $Y$ is the outcome variable and $D$ is the policy variable of interest.
The high-dimensional vector $X = (X_1, \ldots, X_p)$ consists of other confounding covariates,
and $\zeta$ and $V$ are stochastic errors.


### DoubleMLData from `data.table` (recommended)

The R6 class`DoubleMLData` serves as data-backend and can be initialized from a base R `data.frame`, `matrix`  and a `data.table`. First, we generate a `data.table` from the 401_k data set.

```{r}
dt_401k = as.data.table(df_401k)
dt_401k
```

Then set up a new `DoubleMLData` instance. We specify the column ``y_col="net_tfa"`` serving as outcome variable `Y`, the column(s) ``d_cols = 'e401'``  as treatment variable `D` and the columns ``x_cols=['age', 'inc', 'educ', 'fsize', 'marr', 'twoearn', 'db', 'pira', 'hown']`` specifying the control variables. 

```{r}
DoubleML_dt_401k = DoubleMLData$new(dt_401k, 
                                    x_cols = c("age", "inc", "educ", 
                                               "fsize", "marr", "twoearn",
                                               "db", "pira", "hown"), 
                                    y_col = "net_tfa", 
                                    d_cols = "e401")
print(DoubleML_dt_401k)
```


### DoubleMLData from `data.frame`

The function `double_ml_data_from_data_frame` provides an interface to base R `data.frame` objects. The use of the column indices is analogous to instantiation from a `data.table`. 


```{r}
DoubleML_df_401k = double_ml_data_from_data_frame(df_401k,
                                          x_cols = c("age", "inc", "educ", 
                                                      "fsize", "marr", "twoearn",
                                                      "db", "pira", "hown"), 
                                          y_col = "net_tfa", 
                                          d_cols = "e401")
print(DoubleML_df_401k)
```



### DoubleMLData from base R `matrix`

To introduce the `matrix` interface we generate a `matrix` consisting of confounding variables ``X``, an outcome
variable ``y`` and a treatment variable ``d``. 

```{r}
# Generate data
n_obs = 500
n_vars = 100
theta = 3
X = matrix(rnorm(n_obs*n_vars), nrow = n_obs, ncol = n_vars)
d = X[,1:3]%*%c(5,5,5) + rnorm(n_obs)
y = theta*d + X[,1:3] %*% c(5,5,5) + rnorm(n_obs)
```


To specify the data and the variables for the causal model from `matrix` we call

```{r}
DoubleML_data_sim = double_ml_data_from_matrix(X = X, 
                                               y = y, 
                                               d = d)

print(DoubleML_data_sim)
```


### Estimate a causal model with double/debiased machine learning

#### Machine learners to estimate the nuisance models

To estimate our partially linear regression (PLR) model with the double machine learning algorithm, we first have to
specify machine learners to estimate $m_0$ and $g_0$. For the 401(k) data we use :py:class:`~sklearn.ensemble.RandomForestRegressor` from :py:mod:`sklearn.ensemble`
and for our simulated data from a sparse linear model we use
:py:class:`~sklearn.linear_model.Lasso` from :py:mod:`sklearn.linear_model`.

.. ipython:: python

    from sklearn.base import clone
    from sklearn.ensemble import RandomForestRegressor
    from sklearn.linear_model import Lasso

    learner = RandomForestRegressor(max_depth=2, n_estimators=100)
    ml_learners_401k = {'ml_m': clone(learner),
                        'ml_g': clone(learner)}

    learner = Lasso(alpha=np.sqrt(np.log(n_vars)/(n_obs)))
    ml_learners_sim = {'ml_m': clone(learner),
                       'ml_g': clone(learner)}

Cross-fitting, DML algorithms and Neyman-orthogonal score functions
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

When initializing the object for PLR models :class:`~doubleml.double_ml_plr.DoubleMLPLR`, we can further set parameters specifying the
resampling: The number of folds used for cross-fitting ``n_folds`` (defaults to ``n_folds = 5``) as well as the number
of repetitions when applying repeated cross-fitting ``n_rep_cross_fit`` (defaults to ``n_rep_cross_fit = 1``).
Additionally, one can choose between the algorithms ``'dml1'`` and  ``'dml2'`` via ``dml_procedure``. Depending on the
causal model, one can further choose between different Neyman-orthogonal score / moment functions.

DoubleMLPLR: Double/debiased machine learning for partially linear regression models
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

We now initialize :class:`~doubleml.double_ml_plr.DoubleMLPLR` objects for our examples using default parameters

.. ipython:: python

    from doubleml import DoubleMLPLR
    obj_dml_plr_401k = DoubleMLPLR(obj_dml_data_401k, ml_learners_401k)
    obj_dml_plr_sim = DoubleMLPLR(obj_dml_data_sim, ml_learners_sim)

Estimate double/debiased machine learning models
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The models are estimated by calling the ``fit()`` method and we can inspect the estimated treatment effect using the
``summary`` property.

.. ipython:: python

    obj_dml_plr_401k.fit()
    print(obj_dml_plr_401k.summary)

    obj_dml_plr_sim.fit()
    print(obj_dml_plr_sim.summary)
